{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping blog articles for **Migrants' Rights Network**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 3...\n",
      "Saved article: New migration measures reinforce classism and racism\n",
      "Scraping page 4...\n",
      "Saved article: Digital Hostile Environment: Passports and Facial Recognition\n",
      "Saved article: Deprivation of citizenship is Islamophobic\n",
      "Saved article: MAP: Third Workshop\n",
      "Saved article: Digitisation of the UK border: EVisas\n",
      "Saved article: Data-sharing and immigration enforcement\n",
      "Saved article: Suella’s horrendous legacy: her worst moments\n",
      "Saved article: Digitisation of the UK border: Electronic Travel Authorisation (ETA)\n",
      "Saved article: International Day Against Fascism + Antisemitism\n",
      "Saved article: Silent genocides: Congo, Armenia + Sudan\n",
      "Saved article: Desensitisation to the Global Majority’s Suffering\n",
      "Scraping page 5...\n",
      "Saved article: Islamophobia Awareness Month 2023\n",
      "Saved article: Blog: Bibby Stockholm\n",
      "Saved article: “We are pioneers and innovators”.\n",
      "Saved article: “We made ourselves strong”.\n",
      "Saved article: “Celebrating our Blackness in its entirety”.\n",
      "Saved article: Right to Work Checks + Immigration Raids\n",
      "Saved article: MAP: Second Workshop\n",
      "Saved article: Stop Appeasing Your Racist Uncle\n",
      "Saved article: World Mental Health Day\n",
      "Saved article: Black History Month 2023\n",
      "Scraping page 6...\n",
      "Saved article: Identity Trouble: how stereotypes inform Chinese immigrant identification\n",
      "Saved article: “Our heritage is dynamic + constantly changing”\n",
      "Saved article: Open Letter rejecting the Home Secretary’s abhorrent comments\n",
      "Saved article: Everyone has the right to protection\n",
      "Saved article: MAP: First Workshop\n",
      "Saved article: Migrants’ Aspiration Programme for Hongkongers\n",
      "Saved article: Statement: seven day notice eviction period\n",
      "Saved article: Abolition, not reform\n",
      "Saved article: International Day of Charity\n",
      "Saved article: East + South East Asian Heritage Month\n",
      "Scraping page 7...\n",
      "Saved article: Let’s talk about (Brown) sex, baby\n",
      "Saved article: Rebelling against the colonisers\n",
      "Saved article: Open letters: Migrants’ rights organisations call for Government and Labour to abandon support for cruel asylum accommodation\n",
      "Saved article: No to inhumane accommodation- Sign the open letter to shadow cabinet\n",
      "Saved article: No to inhumane accommodation- Sign the open letter to Government\n",
      "Saved article: The Hostile Environment just got worse.\n",
      "Saved article: Stand With Trans\n",
      "Saved article: Statement: citizenship deprivation + the “good character” requirement\n",
      "Saved article: Inhumane Migration Bill: Open Letter\n",
      "Saved article: Trade Unions + Migrant Organisations’ Statement\n",
      "Scraping page 8...\n",
      "Saved article: South Asian Heritage Month\n",
      "Saved article: The inhumane and cruel Migration Bill is set to become law.\n",
      "Saved article: The gender binary is white supremacy\n",
      "Saved article: Disability Pride Month\n",
      "Saved article: How capitalism harms migrants + queer people\n",
      "Saved article: State oppression of queer people\n",
      "Saved article: Biphobia in the UK asylum system\n",
      "Saved article: Why Cypriots should stand in solidarity with refugees\n",
      "Saved article: Scapegoating of migrants, Muslims + queer people: an intersectional perspective\n",
      "Saved article: World Refugee Day\n",
      "Scraping page 9...\n",
      "Saved article: What changes have there been to right to work guidance for employers?\n",
      "Saved article: Survey: Right to Work Checks\n",
      "Saved article: Pride must continue its revolt\n",
      "Saved article: Migration Figures: Statement\n",
      "Saved article: National Conservatism Conference\n",
      "Saved article: Asylum accommodation: what’s going on?\n",
      "Saved article: Multiculturalism and inclusion are not things to be feared\n",
      "Saved article: Immigration Acts 2014 + 2016\n",
      "Saved article: Workers Memorial Day\n",
      "Saved article: We reject the Immigration Minister’s inflammatory remarks.\n",
      "Scraping page 10...\n",
      "Saved article: The Hostile Environment goes digital\n",
      "Saved article: The Data Protection and Digital Information Bill harms migrants’ rights\n",
      "Saved article: Statement on inappropriate refugee accommodation\n",
      "Saved article: RSHE Open Letter: Signatory\n",
      "Saved article: International Day for Elimination of Racial Discrimination\n",
      "Saved article: Commonwealth Day: Our Statement\n",
      "Saved article: What’s going on with the UK’s immigration laws?\n",
      "Saved article: It’s racist to…\n",
      "Saved article: Britain is an expert in homonationalistic ideology\n",
      "Saved article: How Britain exported homophobia\n",
      "Scraping page 11...\n",
      "Saved article: Shamima Begum: Our Statement\n",
      "Saved article: Letter to HMRC and the Home Office on alleged tax discrepancies: Nadhim Zahawi and migrants\n",
      "Saved article: Queerness and Migration\n",
      "Saved article: Joint Letter on Islamophobia, Knowsley and the Far Right\n",
      "Saved article: Cypriot Queerness Beyond Sexuality\n",
      "Saved article: ‘Inclusion’ celebrates who we are\n",
      "Saved article: The burden of explaining where you are from\n",
      "Saved article: Migration discourse is founded on colonial lies\n",
      "Saved article: A story about Akrotiri + Dhekelia\n",
      "Saved article: There are layers to our struggle, and they are all interconnected\n",
      "Scraping page 12...\n",
      "Saved article: Letter to PM on Missing Children\n",
      "Saved article: Letter to the Immigration Minister\n",
      "Saved article: Albania: MRN + JCWI Joint Statement\n"
     ]
    }
   ],
   "source": [
    "def find_date_in_text(text):\n",
    "    \"\"\"Define and apply a regex pattern to extract the date from of 'month date, year' from the text.\"\"\"\n",
    "    pattern = re.compile(r'[a-zA-Z]+ \\d{1,2}, \\d{4}')\n",
    "    match = pattern.search(text)\n",
    "    if match:\n",
    "        return datetime.strptime(match.group(), '%B %d, %Y')\n",
    "    return None\n",
    "\n",
    "def scrape_article(url):\n",
    "    \"\"\"Scrape the article text and publication date from the given URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return None, \"\"\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # target the div containing the article text\n",
    "    article_text = soup.find('div', class_='entry-content clear')\n",
    "    \n",
    "    if article_text:\n",
    "        # extract the text, using 'separator' to add spaces where tags are removed\n",
    "        article_text = article_text.get_text(separator=' ', strip=True)\n",
    "    else:\n",
    "        article_text = \"Could not find the article text.\"\n",
    "        print(f\"Could not extract text for: {url}\")\n",
    "    \n",
    "    # separately finding and extracting the article publication date from the 'entry-meta' div\n",
    "    date_container = soup.find('div', class_='entry-meta')\n",
    "    article_date_text = date_container.get_text(strip=True) if date_container else None\n",
    "    article_date = find_date_in_text(article_date_text) if article_date_text else None\n",
    "\n",
    "    return article_date, article_text\n",
    "\n",
    "def crawl_articles(start_date, end_date, base_url, csv_filename, start_page=3, end_page=12):\n",
    "    \"\"\"Crawl the articles from page 3 to page 12 that were published between the start and end dates.\"\"\"\n",
    "    \"\"\"Save the organisation name, article title, date, link and text to a CSV file.\"\"\"\n",
    "    \"\"\"Delay 1 second between requests to be polite.\"\"\"\n",
    "    start_date = datetime.strptime(start_date, '%d %B %Y')\n",
    "    end_date = datetime.strptime(end_date, '%d %B %Y')\n",
    "\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Organisation', 'Title', 'Date', 'Link', 'Text'])  # Header row\n",
    "\n",
    "        for page in range(start_page, end_page + 1):  # Loop from page 3 to page 12\n",
    "            print(f\"Scraping page {page}...\")\n",
    "            time.sleep(1)  # Wait for 1 second before making each request to be polite\n",
    "            url = f\"{base_url}{page}/\"  # Append the page number to the base URL\n",
    "            response = requests.get(url)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed to fetch {url}\")\n",
    "                continue\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # 'entry-title ast-blog-single-element' is the class for article titles\n",
    "            article_links = soup.findAll('h2', {'class': 'entry-title ast-blog-single-element'})\n",
    "\n",
    "            for link in article_links:\n",
    "                time.sleep(1)  # Polite delay between requests\n",
    "                article_url = link.find('a')['href']\n",
    "                article_date, article_text = scrape_article(article_url)\n",
    "                \n",
    "                if article_date and start_date <= article_date <= end_date:\n",
    "                    writer.writerow([\"Migrants' Rights Network\", link.text.strip(), article_date.strftime('%d %B %Y'), article_url, article_text])\n",
    "                    print(f\"Saved article: {link.text.strip()}\")\n",
    "\n",
    "# execution\n",
    "base_url = 'https://migrantsrights.org.uk/category/blog/page/'\n",
    "csv_filename = '/Users/yijingxiao/Desktop/ASDS dissertation/dissertation-data/article_text.csv'\n",
    "crawl_articles('13 December 2022', '12 December 2023', base_url, csv_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping blog articles for **Freedom from Torture**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 0...\n",
      "Saved article: Supreme Court rules plan to send refugees to Rwanda ‘unlawful’\n",
      "Saved article: Freedom from Torture’s statement on Israel and the Occupied Palestinian Territories\n",
      "Saved article: Bibby Stockholm: Why refugees and torture survivors shouldn’t be housed on floating prisons\n",
      "Saved article: My heart aches for young women imprisoned and suffering in Iran today\n",
      "Saved article: Sunak’s heartless proposal to force refugees to live on barges is a mental and physical health catastrophe waiting to happen\n",
      "Saved article: 'Illegal Migration' Act - Everything you need to know\n",
      "Saved article: Refugee Ban Bill will effectively extinguish the right to seek asylum in the UK\n",
      "Saved article: Where does torture happen around the world?\n",
      "Saved article: What is torture?\n",
      "Saved article: Plan to send refugees to Rwanda ‘unlawful’ – A vital win as the Court of Appeal rules on the Government’s plan\n",
      "Saved article: Banned: A peaceful protest to stand up for refugees\n",
      "Saved article: Freedom from Torture wins top prize at the Charity Awards 2023\n",
      "Saved article: Bridgerton star Adjoa Andoh presents Freedom from Torture’s BBC Radio 4 Appeal\n"
     ]
    }
   ],
   "source": [
    "def find_date_in_text(text):\n",
    "    \"\"\"Define and apply a regex pattern to extract the date from of 'date month year' from the text.\"\"\"\n",
    "    pattern = re.compile(r'\\d{1,2} [a-zA-Z]+ \\d{4}')\n",
    "    match = pattern.search(text)\n",
    "    if match:\n",
    "        return datetime.strptime(match.group(), '%d %B %Y')\n",
    "    return None\n",
    "\n",
    "def scrape_article(url):\n",
    "    \"\"\"Scrape the article text and publication date from the given URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching article: {url}\")\n",
    "        return None, \"\", \"\"\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    article_content = soup.find('div', {'class': 'last-unspace'})\n",
    "    article_text = article_content.get_text(separator=' ', strip=True) if article_content else \"Could not find the article text.\"\n",
    "    \n",
    "    date_container = soup.find('div', class_='field--field-published-date--item')\n",
    "    article_date_text = date_container.get_text(strip=True) if date_container else None\n",
    "    article_date = find_date_in_text(article_date_text) if article_date_text else None\n",
    "\n",
    "    return article_date, article_text\n",
    "\n",
    "def strip_date_from_title(title_with_date):\n",
    "    \"\"\"Delete the date at the start of the title and any following newlines/spaces.\"\"\"\n",
    "    pattern = re.compile(r'^\\d{1,2} [a-zA-Z]+ \\d{4}\\s*[\\n\\r\\s]*')\n",
    "    # Replace the matched date and following whitespace/newlines with an empty string\n",
    "    title_without_date = re.sub(pattern, '', title_with_date).strip()\n",
    "    return title_without_date\n",
    "\n",
    "def crawl_articles(start_date, end_date, base_url, csv_filename, start_page=0, end_page=0):\n",
    "    \"\"\"Crawl the articles on page0 that were published between the start and end dates.\"\"\"\n",
    "    \"\"\"Save the organisation name, article title, date, link and text to a CSV file.\"\"\"\n",
    "    \"\"\"Delay 1 second between requests to be polite.\"\"\"\n",
    "    start_date = datetime.strptime(start_date, '%d %B %Y')\n",
    "    end_date = datetime.strptime(end_date, '%d %B %Y')\n",
    "\n",
    "    with open(csv_filename, 'a', newline='', encoding='utf-8') as file:  # 'a' mode for appending\n",
    "        file.seek(0, os.SEEK_END)\n",
    "        if file.tell() != 0:  # File is not empty\n",
    "            file.write('\\n')  # Ensure starts on a new line\n",
    "        \n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        for page in range(start_page, end_page + 1):\n",
    "            print(f\"Scraping page {page}...\")\n",
    "            time.sleep(1)\n",
    "            page_url = f\"{base_url}?page={page}\" \n",
    "            response = requests.get(page_url)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed to fetch {page_url}\")\n",
    "                continue\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            article_links = soup.findAll('div', {'class': 'mb-4'})\n",
    "\n",
    "            for link in article_links:\n",
    "                time.sleep(1)  # Polite delay between requests\n",
    "                a_tag = link.find('a')\n",
    "                if a_tag and a_tag['href']:\n",
    "                    article_url = a_tag['href']\n",
    "                    # Check if the URL is relative and prepend the base URL if necessary\n",
    "                    if article_url.startswith('/'):\n",
    "                        article_url = f\"https://www.freedomfromtorture.org{article_url}\"\n",
    "                    article_date, article_text = scrape_article(article_url)\n",
    "                                \n",
    "                    if article_date and start_date <= article_date <= end_date:\n",
    "                        article_title_with_date = link.text.strip()  # Original text containing both title and date\n",
    "                        article_title = strip_date_from_title(article_title_with_date)  # Stripped title\n",
    "                        writer.writerow([\"Freedom from Torture\", article_title, article_date.strftime('%d %B %Y'), article_url, article_text])\n",
    "                        print(f\"Saved article: {article_title}\")\n",
    "\n",
    "\n",
    "# execution\n",
    "base_url = 'https://www.freedomfromtorture.org/news'\n",
    "csv_filename = '/Users/yijingxiao/Desktop/ASDS dissertation/dissertation-data/article_text.csv'\n",
    "crawl_articles('13 December 2022', '12 December 2023', base_url, csv_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
